\section{Day 1: Introduction to Probability (Sep. 4, 2024)}
Link to \href{https://drive.google.com/file/d/1Rpkr-NCEyqygvypR65RznaZkb36KHB29/view}{textbook}.
\medskip\newline
We start with a sampler problem that on the surface, seems unrelated to probability. Let $v_1, \dots, v_n \in \RR^n$ be unit vectors on the unit sphere, i.e.t $\norm{v_i} = 1$. If we are to pick $\eps_i = \{-1, 1\}$ at random, what is our expectation on how large will
\[ \sum_{i=1}^n \eps_i v_i \]
be? We could brute force and average out over all probabilities as follows,
\[ \frac{1}{2^n} \sum_{\eps \in \{-1, 1\}^n} \left(\sum_{i=1}^n \eps_i v_i \right) = \sum_{i=1}^n \left(\frac{1}{2^n} \underbrace{\sum_{\eps \in \{-1, 1\}^n} \eps_i}_{=0} \right) v_i = 0. \]
Now, consider that
\begin{align*}
    \frac{1}{2^n} \sum_{\eps \in \{-1, 1\}^n} \abs{\sum_{i=1}^n \eps_i v_i}^2 &= \frac{1}{2^n} \sum_{\eps \in \{-1, 1\}^n} \sum_{i_1, i_2 = 1}^n \eps_{i_1} \eps_{i_2} \left< v_{i_1}, v_{i_2} \right> \\
    &= \sum_{i_1, i_2 = 1}^n \left(\frac{1}{2^n} \sum_{\eps \in \{-1, 1\}^n} \eps_{i_1} \eps_{i_2} \right) \left< v_{i_1}, v_{i_2} \right>
\end{align*}
To simplify the bracketed summation, we could consider the following two cases:
\begin{itemize}
    \item If $i_1 \neq i_2$, we would have that
    \[ \frac{1}{2^n} \sum_{\eps \in \{-1, 1\}^n} \eps_{i_1} \eps_{i_2} = \frac{2^{n-2}}{2^n} \sum_{\substack{\eps_{i_1} \in \{-1, 1\} \\ \eps_{i_2} \in \{-1, 1\}}} \eps_{i_1} \eps_{i_2} = 0. \]
    \item If $i_1 = i_2$, we would have
    \[ \frac{1}{2^n} \sum_{\eps \in \{-1, 1\}^n} \eps_{i_1} \eps_{i_2} = \frac{2^{n-1}}{2^n} \sum_{\eps_i \in \{-1, 1\}} \eps_{i_1} \eps_{i_2} = 1. \]
\end{itemize}
By linearity of expectation, we obtain
\[ \frac{1}{2^n} \sum_{\eps \in \{-1, 1\}^n} \abs{\sum_{i=1}^n \eps_i v_i}^2 = n, \]
and
\[ \frac{1}{2^n} \sum_{\eps \in \{-1, 1\}^n} \abs{\sum_{i=1}^n \eps_i v_i} = c\sqrt{n}, \]
where $c$ is a positive real constant.

\newpage
\noindent We now abstract a few probability terms;
\begin{itemize}
    \item $\Omega$ is a sample space, i.e. the set of possible outcomes.
    \item Let $P$ denote probability, i.e. a mapping of subsets of $\Omega$ to $[0, 1]$ (read: probability of getting these subsets of $\Omega$); the probability of an event $\eps$ out of $S$ occuring is given by $P(\eps \in S, S \subset \{-1, 1\}^n) = \frac{1}{\abs{S}}$, assuming that each event in $S$ is equally likely. With this, we have three important properties of $P$ to define:
    \begin{enumerate}
        \item $P(\Omega) = 1$; the chance of an event in the probability space happening is $1$.
        \item Let $\SF$ be a collection of subsets $A_1, \dots, A_n$. Then
        \[ P\left( \bigcup_{i=1}^n A_i \right) = \sum_{i=1}^n P(A_i), \]
        given that $A_i \cap A_j = \emptyset$ for all $1 \leq i, j \leq n$. This is linearity of expectation.
        \item $P(A^C) = 1 - P(A)$, which is a property of set complement. 
    \end{enumerate}
    \item When our collection $\SF$ of subsets of $\Omega$ satisfy the following properties, we call it a $\sigma$-algebra:
    \begin{enumerate}
        \item $\emptyset \in \SF$,
        \item Closed under countable union: $A_n \in \SF \implies \bigcup_{i=1}^n A_i \in \SF$,
        \item Closed under complement: $A_i \in \SF \implies A_i^C \in \SF$.
    \end{enumerate}
    In a finite sample space, the power set $\SF = \SP(\Omega)$ is one such example of a $\sigma$-algebra. As an example, let $\Omega = [0, 1)$; then $P([a, b]) = b - a$ (wlog, let $a < b$). Now, let $\SF = \SP([0, 1))$. Define the equivalence $x \sim y$ if $x - y \in \QQ$.
    \item We now introduce the axiom of choice; Let $A$ be a set containing one element of each equivalence class from the above defined equivalence. Consider $\tau_q A := \{A\} + q$; let us claim that
    \[ \bigcup_{q \in \QQ} \tau_q A = [0, 1), \]
    which is a countable union of $[0, 1)$, since $\QQ$ is countable. We have that $P(A) = P(\tau_q A)$ because intervals don't change size under shifting by $q$. However, observe that
    \[ P([0, 1)) = P\left( \bigcup_{q \in \QQ} \tau_q A \right) = \sum_{q \in \QQ} P(\tau_q A). \]
    Then either
    \begin{align*}
        P(A) &= 0 \implies P(\tau_q A) = 0 \implies P([0, 1)) = 0, \text{or} \\
        P(A) &\neq 0 \implies P(\tau_q A) \to \infty \implies P([0, 1)) \to \infty,
    \end{align*}
    which doesn't make sense (for now). This shows that we need to pick our $\sigma$-algebra properly; observing that the intersection of two $\sigma$-algebras is also a $\sigma$-algebra, it is appropriate to let $\SF$ be the smallest $\sigma$-algebra containing $[a, b)$. This is called a \textit{Borel Set}.
\end{itemize}
