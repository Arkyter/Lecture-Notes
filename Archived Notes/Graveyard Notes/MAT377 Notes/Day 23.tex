\section{Day 23: Markov Chains, Pt. 2 (Dec. 2, 2024)}
Let $S = \{s_1, \dots, s_m\}$ be a finite set of states; consider the chain $X_0 = s_1, X_1, \dots$, and let $T = \min\{ n \geq 1 \mid X_n = S_1 \}$ be the ``return time''. If the Markov chain does not start at $s_1$, this is called a ``hitting time'' of $s_1$. In particular, it is an example of a \textit{stopping time}, i.e. $T$ is a stopping time if $1\{T = n\} = f_n(X_0, \dots, X_n)$. Note that
\begin{align*}
    S &= \text{last time we visited} s_1 \text{ is not a stopping time.} \\
    U &= T - 1 \text{ is not a stopping time.}
\end{align*}
We may write $P(X_{k+1} = x_{k+1} \mid X_0 = x_0, \dots, X_k = x_k) = P(X_{k+1} = x_{k+1} \mid X_k = x_k)$. The Markov property generalizes to functions (??). If $T$ is a stopping time with $T < \infty$, then $P(y(X_T + \dots) \mid X_0 = x_0, \dots, X_T = x_T) = P(g(X_0 + \dots) \mid X_0 = x_T)$. We now prove it for hitting times.
\begin{align*}
    & P(g(X_T + \dots) = a \mid X_0 = x_0, \dots, X_T = s_1) \\
    &= P(g(X_0 + \dots) = a \mid X_0 = s_1).
\end{align*}
This is called the \textit{strong Markov property}. Directly write as follows,
\begin{align*}
    & P(g(X_T + \dots) = a \mid X_0 = x_1, \dots, X_T = s_1, T = n) \\
    &= P(g(X_n + \dots) = a, X_0 = x_1, \dots, X_n = S_1, T = n) \\
    &= P(g(X_n + \dots) = a \mid X_n = s_1) P(X_0 = x_1, \dots, X_n = s_1, T = n). 
\end{align*}
Summing over $n$, we get that $P(g(X_T + \dots) = a, X_0 = x_1, \dots, X_T = s_1) = P(g(X_0 + \dots) = a \mid X_0 = s_1) P(X_0 = x_1, \dots, X_T = s_1)$. Recall that we showed that if a Markov chain is aperiodic and irreducible, then
\[ \lim_{n \to \infty} \EE \left[ \frac{1}{n} \sum_{k=1}^m 1(X_k = s_i) \right] = \mu_j \] 
in time $t$ up to $n$ it returns to $s_1$, at times $T_1, T_1 + T_2, T_1 + T_2 + T_3, \dots, T_1 + \dots + T_L$. $L$ is the number of times that you came back to $s_1$ in $\{1, \dots, n\}$. Note that $T_1, \dots, T_L$ are independent and identically distributed. Consider $N_1(j), \dots, N_L(j)$, where $N_i(j)$ are the number of vists to $s_j$ on $T_1 + \dots + T_i$, $T_1 + \dots + T_{i+1}$. Also note that each $N_i(j)$ is i.i.d., except we just don't know the distributino. Then
\[ N_1(j) + \dots + N_L(j) \sim \sum_{i=1}^n 1(X_i = s_j); \hspace{0.2in} \frac{1}{n} \sum_{k=1}^n 1(X_k = s_j) \sim \frac{N_1(j) + \dots + N_L(j)}{T_1 + \dots + T_L}. \]
As $n \to \infty$, we have that
\[ \frac{\EE N_i(j)}{\EE T_i} = \mu_j, \]
which implies that
\begin{enumerate}[label=(\roman*)]
    \item $\lim_{n \to \infty} \sum_{k=1}^n f(X_k) = \sum_j f(s_j) \mu_j$. This is an Ergodic theorem, and this is true for any $f$ on $S$.
    \item $\mu_j = \dfrac{\EE N_1(j)}{\EE T_1}$. In particular, any state works.
\end{enumerate}

\newpage
\noindent We now introduce the Metropolis algorithm. Let $S = \{s_1, \dots, s_m\}$ be a graph, where $s_i$ has $N_i$ neighbors (which we say $s_i \sim s_j$ if they are neighbors). Let
\[ p_{ij} = \begin{cases} \frac{1}{N_i} \min\{\frac{\mu_j N_i}{\mu_i N_j}, 1\} & s_j \sim s_1, \\ 1 - \sum_{s_j \sim s_i} p_{ij} & i = j, \\ 0 & \text{otherwise.} \end{cases} \]
This chain has $\mu_i$ as its stationary (reversible) distribution, i.e.
\begin{align*}
    \frac{1}{n} \sum_{k=1}^\infty f(X_k) &\to \sum_{i} f(s_i) \mu_i, \\
    \frac{1}{n} \sum_{k=1}^\infty 1(X_k = s_i) &\to \mu_i.
\end{align*}
I'm not recording the Ising mnodel. Not sure where we're going with that.
\medskip\newline
Consider the riffle shuffle; cut a deck of $n$ cards into $c, n-c$ with probability $\binom{n}{c} 2^{-n}$. If $A$ cards are on the left,  $B$ are on the right, the chance of the next card from the left is $\frac{A}{A + B}$, and $\frac{B}{A + B}$. 